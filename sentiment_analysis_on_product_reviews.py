# -*- coding: utf-8 -*-
"""Task_1:Sentiment_Analysis_on_Product_Reviews.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IXzfq0mdwPQV0KQQT0mPALLaXT8MW3K8
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import shutil
import textwrap
from getpass import getpass

username = "meenuslog"
repo_name = "sentiment_analysis"
token = getpass("Enter your GitHub token: ")

repo_url = f"https://{token}@github.com/{username}/{repo_name}.git"

# Now clone fresh
!git clone $repo_url



repo_path = f"/content/{repo_name}"
os.makedirs(f"{repo_path}/data", exist_ok=True)

# Move the IMDB dataset into repo's data directory
!cp "/content/IMDB Dataset.csv" "{repo_path}/data/IMDB_Dataset.csv"

# # Remove this block to ensure dataset is NOT ignored
# with open(f"{repo_path}/.gitignore", "w") as f:
#     f.write("data/IMDB_Dataset.csv\n")

readme_content = textwrap.dedent("""
    # IMDB Movie Reviews Sentiment Analysis

    This repository contains code for performing sentiment analysis on the IMDB movie reviews dataset.

    ## Requirements

    **install individually:**

    ```bash
    pip install pandas numpy scikit-learn matplotlib seaborn spacy tqdm gdown
    ```
""")

with open(f"{repo_path}/README.md", "w") as f:
    f.write(readme_content)

# Add, commit, and push repo changes
# %cd {repo_path}
!git config --global user.email "emaan.yawer.19@gmail.com"
!git config --global user.name "meenuslog"

!git add .
!git commit -m "Initial commit with README and dataset included"
!git push origin main

"""###**DATASET LOADING**"""

import pandas as pd

try:
    df = pd.read_csv('/content/IMDB Dataset.csv', engine='python')
    print(df.head())
except Exception as e:
    print(f"An error occurred: {e}")

"""### **ENCODING SENTIMENTS**


"""

df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})

"""### **Pre-Processing Reviews**  (using spaCy)"""

!pip install -U spacy
!python -m spacy download en_core_web_sm

import spacy
import re
from tqdm import tqdm

# spaCy English model
nlp = spacy.load("en_core_web_sm", disable=["ner", "parser"])

# cleaning function
def clean_review(text):
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    doc = nlp(text.lower())
    tokens = [token.lemma_ for token in doc
              if token.is_alpha and not token.is_stop and len(token) > 2]
    return ' '.join(tokens)

# tqdm progress bar
tqdm.pandas(desc="Cleaning with spaCy")
df['cleaned_review'] = df['review'].progress_apply(clean_review)

"""### **TF-IDF Vectorization**"""

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df['cleaned_review'])
y = df['sentiment'].map({'positive': 1, 'negative': 0})  # Convert labels to binary

df['sentiment'].value_counts(dropna=False)

print(df['sentiment'].unique())

y = df['sentiment'].astype(int)

"""### **Train/Test Split**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

"""### **Train Logistic Regression Model**"""

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

"""### **Evaluate the Model**"""

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

"""### **BONUS TASKS**

## **Visualization**
"""

from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns

# Separate positive and negative reviews
positive_reviews = df[df['sentiment'] == 1]['cleaned_review']
negative_reviews = df[df['sentiment'] == 0]['cleaned_review']
pos_words = ' '.join(positive_reviews).split()
neg_words = ' '.join(negative_reviews).split()
# Count word frequencies
pos_counts = Counter(pos_words).most_common(20)
neg_counts = Counter(neg_words).most_common(20)

# Convert to DataFrame for plotting
pos_df = pd.DataFrame(pos_counts, columns=['word', 'count'])
neg_df = pd.DataFrame(neg_counts, columns=['word', 'count'])

# Positive
plt.figure(figsize=(10,5))
sns.barplot(data=pos_df, x='count', y='word', palette='Greens_r')
plt.title("Top 20 Words in Positive Reviews")
plt.show()
# Negative
plt.figure(figsize=(10,5))
sns.barplot(data=neg_df, x='count', y='word', palette='Reds_r')
plt.title("Top 20 Words in Negative Reviews")
plt.show()

"""## **Applying Naive Bayes**"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Vectorize (reuse your CountVectorizer or use TF-IDF)
from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df['cleaned_review'])
y = df['sentiment']

# Train-test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Train Naive Bayes
nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)

# Predict
y_pred_nb = nb_model.predict(X_test)
print("Naive Bayes Accuracy:", accuracy_score(y_test, y_pred_nb))
print("\nClassification Report:\n", classification_report(y_test, y_pred_nb))